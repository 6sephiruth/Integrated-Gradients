{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow_hub\n",
    "#!pip install bert-tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import bert\n",
    "from bert import tokenization\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_model_utils import transform_input, generate_baseline, get_ig_attributions, visualize_token_attrs, get_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1111 03:29:29.183141 139904582027072 deprecation.py:323] From <ipython-input-3-1491798eed86>:4: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "W1111 03:29:31.317682 139904582027072 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1282: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Tensorflow Session and load the saved model\n",
    "SESS = tf.Session()\n",
    "SAVED_MODEL_PATH = 'bert_saved_model_sep19/1568924123'\n",
    "saved_model = tf.saved_model.loader.load(sess=SESS, tags=['serve'], export_dir=SAVED_MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1111 03:29:33.593637 139904582027072 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Define the input tensors using the SignatureDef\n",
    "INPUT_TENSORS = saved_model.signature_def[\"serving_default\"].inputs\n",
    "\n",
    "# Get output tensor for model using the SignatureDef\n",
    "OUTPUT_TENSOR = get_tensor(SESS, saved_model.signature_def[\"serving_default\"].outputs['probabilities'].name)\n",
    "\n",
    "# Path to Tokenizer\n",
    "TOKENIZER_PATH = 'bert_tokenizer.pkl'\n",
    "with open(TOKENIZER_PATH, 'rb') as file:\n",
    "    TOKENIZER = pickle.load(file)\n",
    "    \n",
    "# The embedding tensor of the model\n",
    "EMBEDDING_TENSOR = get_tensor(SESS, 'module_apply_tokens/bert/embeddings/add_1:0')\n",
    "\n",
    "# Gradient tensor of output wrt embedding tensor\n",
    "GRADIENT_TENSOR = tf.gradients(OUTPUT_TENSOR[:, 1], EMBEDDING_TENSOR)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction is 1.955999141500797e-05\n",
      "baseline_prediction is 0.4553076922893524\n",
      "delta_prediction is -0.4552881419658661\n",
      "sum_attributions are -0.4555169343948364\n",
      "Error percentage is -0.050252226641011435\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <span style='color:rgb(115,154,115)'>this </span> <span style='color:rgb(136,124,124)'>was </span> <span style='color:rgb(154,115,115)'>an </span> <span style='color:rgb(255,64,64)'>awful </span> <span style='color:rgb(149,117,117)'>movie </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction is 0.9998936653137207\n",
      "baseline_prediction is 0.4553076922893524\n",
      "delta_prediction is 0.5445859432220459\n",
      "sum_attributions are 0.568222165107727\n",
      "Error percentage is -4.340218872679179\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <span style='color:rgb(108,168,108)'>this </span> <span style='color:rgb(102,180,102)'>was </span> <span style='color:rgb(121,142,121)'>a </span> <span style='color:rgb(64,255,64)'>good </span> <span style='color:rgb(160,112,112)'>movie </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction is 8.560651622246951e-05\n",
      "baseline_prediction is 0.49438032507896423\n",
      "delta_prediction is -0.4942947328090668\n",
      "sum_attributions are -0.4316096305847168\n",
      "Error percentage is 12.68172571212965\n",
      "Num reps is 6, abs error percentage is 12.68172571212965\n",
      "prediction is 8.560651622246951e-05\n",
      "baseline_prediction is 0.49438032507896423\n",
      "delta_prediction is -0.4942947328090668\n",
      "sum_attributions are -0.4943336844444275\n",
      "Error percentage is -0.007880244877252977\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <span style='color:rgb(119,145,119)'>this </span> <span style='color:rgb(127,129,127)'>was </span> <span style='color:rgb(255,64,64)'>not </span> <span style='color:rgb(156,114,114)'>a </span> <span style='color:rgb(106,172,106)'>good </span> <span style='color:rgb(164,110,110)'>movie </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction is 0.9999759197235107\n",
      "baseline_prediction is 0.5354936718940735\n",
      "delta_prediction is 0.46448224782943726\n",
      "sum_attributions are 1.131194829940796\n",
      "Error percentage is -143.53887263226096\n",
      "Num reps is 6, abs error percentage is -143.53887263226096\n",
      "prediction is 0.9999759197235107\n",
      "baseline_prediction is 0.5354936718940735\n",
      "delta_prediction is 0.46448224782943726\n",
      "sum_attributions are 0.3986581265926361\n",
      "Error percentage is 14.171504195133945\n",
      "Num reps is 11, abs error percentage is 14.171504195133945\n",
      "prediction is 0.9999759197235107\n",
      "baseline_prediction is 0.5354936718940735\n",
      "delta_prediction is 0.46448224782943726\n",
      "sum_attributions are 0.4558603763580322\n",
      "Error percentage is 1.856232721852283\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <span style='color:rgb(113,157,113)'>this </span> <span style='color:rgb(155,114,114)'>was </span> <span style='color:rgb(255,64,64)'>not </span> <span style='color:rgb(110,164,110)'>a </span> <span style='color:rgb(82,220,82)'>great </span> <span style='color:rgb(162,111,111)'>movie </span> <span style='color:rgb(125,133,125)'>, </span> <span style='color:rgb(115,154,115)'>but </span> <span style='color:rgb(105,174,105)'>a </span> <span style='color:rgb(67,250,67)'>good </span> <span style='color:rgb(160,112,112)'>movie </span> <span style='color:rgb(120,144,120)'>nevertheless </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction is 1.669874654908199e-05\n",
      "baseline_prediction is 0.5070011615753174\n",
      "delta_prediction is -0.5069844722747803\n",
      "sum_attributions are -0.5019686818122864\n",
      "Error percentage is 0.9893380836672628\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <span style='color:rgb(100,184,100)'>this </span> <span style='color:rgb(172,106,106)'>was </span> <span style='color:rgb(125,133,125)'>a </span> <span style='color:rgb(255,64,64)'>terrible </span> <span style='color:rgb(180,102,102)'>movie </span> <span style='color:rgb(150,117,117)'>. </span> <span style='color:rgb(151,116,116)'>do </span> <span style='color:rgb(135,124,124)'>you </span> <span style='color:rgb(117,149,117)'>agree </span> <span style='color:rgb(165,109,109)'>? </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame structure that we will input into the model\n",
    "sentences = ['This was an awful movie', 'This was a good movie', 'This was not a good movie', \n",
    "             'This was not a great movie, but a good movie nevertheless',\n",
    "            'This was a terrible movie. Do you agree?']\n",
    "\n",
    "input_df = pd.DataFrame(columns=['sentence'], data=sentences)\n",
    "\n",
    "\n",
    "\n",
    "for sentence in sentences:\n",
    "    input_df['sentence'][0] = sentence\n",
    "    transformed_input_df = transform_input(TOKENIZER, input_df.head(1))\n",
    "    baseline_df = generate_baseline(TOKENIZER, input_df.head(1))\n",
    "    ig = get_ig_attributions(sess=SESS, \n",
    "                             input_tensors=INPUT_TENSORS, \n",
    "                             embedding_tensor=EMBEDDING_TENSOR,\n",
    "                             gradient_tensor=GRADIENT_TENSOR, \n",
    "                             output_tensor=OUTPUT_TENSOR, \n",
    "                             transformed_input_df=transformed_input_df,\n",
    "                             baseline_df=baseline_df, \n",
    "                             tokenizer=TOKENIZER)\n",
    "    display(visualize_token_attrs(ig['outputs'][0], np.array(ig['outputs'][1])))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Predicting Movie Reviews with BERT on TF Hub.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
